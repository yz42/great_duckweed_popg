#! /bin/bash

# gridss.post_process.sbatch

#SBATCH --export=ALL               # Start with a clean environment
#SBATCH --nodes=1                   # the number of nodes you want to reserve
#SBATCH --ntasks-per-node=2      # the number of CPU cores per node
#SBATCH --mem=8G                 # how much memory is needed per node (units can be: K, M, G, T)
#SBATCH --partition=normal          # on which partition to submit the job
#SBATCH --time=1:00:00             # the max wallclock time (time limit your job will run)
#SBATCH --job-name=gridss.post_process       # the name of your job
#SBATCH -o ./out_err/gridss.post_process_%A_%a.out # Standard output
#SBATCH -e ./out_err/gridss.post_process_%A_%a.err # Standard error

module load palma/2020b Java/11.0.2 GCC/10.2.0  OpenMPI/4.0.5 R/4.0.3 SAMtools/1.11


FILES=($(cat vcf.list))
i=${FILES[$SLURM_ARRAY_TASK_ID]}
j=$(basename $i .vcf)
# FILENAME=${j%%.*} 

echo "file: $i"
echo "array ID: $SLURM_ARRAY_TASK_ID"

module load palma/2020b  GCC/10.2.0  OpenMPI/4.0.5 R/4.0.3 BCFtools/1.11

mkdir -p ./anno_vcf ./anno_bed
Rscript /scratch/tmp/ywang1/01.duckweed/popgenomics/SV/GRIDESS/post_process/simple-event-annotation.customized.R $i

bgzip -c ./anno_vcf/$j.vcf.anno.vcf > ./anno_vcf/$j.vcf.anno.vcf.gz
tabix -p vcf ./anno_vcf/$j.vcf.anno.vcf.gz





FILES=($(cat vcf.list))
# get size of array
NUMFASTQ=${#FILES[@]}
# now subtract 1 as we have to use zero-based indexing (first cell is 0)
ZBNUMFASTQ=$(($NUMFASTQ - 1))
# now submit to SLURM
if [ $ZBNUMFASTQ -ge 0 ]; then
    echo "start with $ZBNUMFASTQ" 
    sbatch --array=0-$ZBNUMFASTQ gridss.post_process.sbatch
fi