#! /bin/bash
# blast2ref.sbatch

#SBATCH --export=ALL              # Start with a clean environment
#SBATCH --nodes=1                   # the number of nodes you want to reserve
#SBATCH --ntasks-per-node=64        # the number of CPU cores per node
#SBATCH --mem=32G                 # how much memory is needed per node (units can be: K, M, G, T)
#SBATCH --partition=normal          # on which partition to submit the job
#SBATCH --time=24:00:00             # the max wallclock time (time limit your job will run)
#SBATCH --job-name=blast2ref       # the name of your job
#SBATCH -o ./log_err/blast2ref_%A_%a.out # Standard output
#SBATCH -e ./log_err/blast2ref_%A_%a.err # Standard error

FILES=($(cat split100.list))
i=${FILES[$SLURM_ARRAY_TASK_ID]}
FILENAME=$(basename $i .fa)


echo "$FILENAME"
echo "$SLURM_ARRAY_TASK_ID"

module load  palma/2020b  GCC/10.2.0

blastp -query $i -db /scratch/tmp/xus/database/RefSeqPlant -out ./out/$FILENAME.out -outfmt 5 -num_alignments 20 -evalue 1e-3 -num_threads 64





FILES=($(cat split100.list))
# get size of array
NUMFASTQ=${#FILES[@]}
# now subtract 1 as we have to use zero-based indexing (first cell is 0)
ZBNUMFASTQ=$(($NUMFASTQ - 1))
# now submit to SLURM
if [ $ZBNUMFASTQ -ge 0 ]; then
	echo "start with $ZBNUMFASTQ"
	sbatch --array=0-$ZBNUMFASTQ blast2ref.sbatch
fi

